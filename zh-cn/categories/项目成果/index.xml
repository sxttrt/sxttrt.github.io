<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>项目成果 on 刘承韬</title>
        <link>https://sxttrt.github.io/zh-cn/categories/%E9%A1%B9%E7%9B%AE%E6%88%90%E6%9E%9C/</link>
        <description>Recent content in 项目成果 on 刘承韬</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>刘承韬</copyright>
        <lastBuildDate>Fri, 20 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://sxttrt.github.io/zh-cn/categories/%E9%A1%B9%E7%9B%AE%E6%88%90%E6%9E%9C/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>基于强化学习的倒立摆控制与双足机器人系统构建</title>
        <link>https://sxttrt.github.io/zh-cn/p/rl-control-project/</link>
        <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
        
        <guid>https://sxttrt.github.io/zh-cn/p/rl-control-project/</guid>
        <description>&lt;img src="https://sxttrt.github.io/RL/fengmian.png" alt="Featured image of post 基于强化学习的倒立摆控制与双足机器人系统构建" /&gt;&lt;!-- 完整MathJax配置（加载+识别规则），复制到文章开头即可 --&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;script&gt;
// 明确MathJax的公式识别规则，避免冲突
MathJax.config = {
  tex: {
    inlineMath: [[&#39;$&#39;, &#39;$&#39;], [&#39;\\(&#39;, &#39;\\)&#39;]],  // 行内公式：$...$ 或 \(...\)
    displayMath: [[&#39;$$&#39;, &#39;$$&#39;], [&#39;\\[&#39;, &#39;\\]&#39;]],  // 行间公式：$$...$$ 或 \[...\]
    processEscapes: true,  // 允许反斜杠转义（比如 \sum、\mu 正常生效）
    processEnvironments: true  // 支持复杂公式环境（如矩阵、分段函数）
  },
  svg: {
    fontCache: &#39;global&#39;  // 缓存字体，加快渲染速度
  }
};
&lt;/script&gt;
&lt;h2 id=&#34;一项目核心信息&#34;&gt;一、项目核心信息
&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;信息类别&lt;/th&gt;
          &lt;th&gt;具体内容&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;项目名称&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;基于强化学习的倒立摆控制与双足机器人系统构建&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心成员&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;刘承韬、张皓佳、马博涵&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心任务&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;1. 倒立摆：① 基于LQR的线性控制（动力学建模、线性化、离散化）；② 基于REINFORCE的强化学习控制（策略梯度算法部署、奖励函数设计）；&lt;br&gt;2. 双足机器人：① Isaac Gym/MuJoCo仿真环境搭建；② PPO算法训练框架部署；③ 分层奖励函数设计；④ 平衡-步态稳定-复杂地形适配三级训练链路构建；⑤ 非结构化地形自适应行走实现&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;关键工具&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Python、PyTorch（强化学习框架）、NumPy（矩阵计算）、Isaac Gym（并行仿真）、MuJoCo（高精度仿真）、Gymnasium（倒立摆REINFORCE环境）、Matplotlib（可视化）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;二项目背景与目标&#34;&gt;二、项目背景与目标
&lt;/h2&gt;&lt;h3 id=&#34;1-项目背景&#34;&gt;1. 项目背景
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;倒立摆系统&lt;/strong&gt;：作为经典非线性、不稳定控制对象，其平衡控制是验证控制算法有效性的典型场景。传统线性控制（如LQR）依赖精确建模，鲁棒性有限；强化学习（如REINFORCE）通过智能体与环境交互试错，可自主学习最优策略，无需依赖显式模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;双足机器人&lt;/strong&gt;：具备卓越的地形适应能力，在搜救、勘探、物流等领域潜力巨大，但高维、非线性的动态特性导致其步态稳定与复杂环境适配成为核心挑战。传统控制（如ZMP）需精确建模与复杂计算，对环境变化鲁棒性不足；深度强化学习（DRL）可发现非直观且高效的控制策略，适配高维系统需求。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本项目分别针对两类系统，通过传统控制与强化学习方法，解决倒立摆平衡控制与双足机器人行走控制问题。&lt;/p&gt;
&lt;h3 id=&#34;2-核心目标&#34;&gt;2. 核心目标
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;倒立摆控制目标&lt;/strong&gt;：① 基于LQR实现倒立摆线性控制（完成变量替换、线性化、离散化全流程，验证多初始角稳定控制）；② 基于REINFORCE实现倒立摆强化学习控制（设计多维度奖励函数，实现微扰下长时间平衡）；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;双足机器人目标&lt;/strong&gt;：① 搭建Isaac Gym并行仿真训练框架，部署PPO算法；② 设计分层奖励函数，解决默认训练5000轮后策略崩溃、小碎步步态、零指令下滑动等问题；③ 构建三级训练链路，实现平地行走、抗扰动、复杂地形（斜坡、非平整地面）自适应行走；④ 完成Sim-to-Sim迁移（Isaac Gym训练策略迁移至MuJoCo验证）；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工程化目标&lt;/strong&gt;：所有算法模块化封装，配套仿真可视化素材，确保实验过程可复现。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三核心任务实现&#34;&gt;三、核心任务实现
&lt;/h2&gt;&lt;h3 id=&#34;任务一倒立摆控制lqr线性控制--reinforce强化学习控制&#34;&gt;任务一：倒立摆控制（LQR线性控制 + REINFORCE强化学习控制）
&lt;/h3&gt;&lt;h4 id=&#34;1-基于lqr的倒立摆线性控制文档2最优projectdocx&#34;&gt;1. 基于LQR的倒立摆线性控制（文档2：最优project.docx）
&lt;/h4&gt;&lt;h5 id=&#34;1动力学建模与线性化离散化&#34;&gt;（1）动力学建模与线性化、离散化
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;变量替换&lt;/strong&gt;：定义状态变量以简化动力学方程：
$$x_1=z \quad (\text{小车位置}),\quad x_2=\pi-\theta \quad (\text{摆杆角度转换}),\quad x_3=\dot{z} \quad (\text{小车速度}),\quad x_4=\dot{\theta} \quad (\text{摆杆角速度})$$
通过三角函数变换：
$$\sin\theta = \sin(\pi-x_2) = \sin x_2,\quad \cos\theta = \cos(\pi-x_2) = -\cos x_2$$
代入系统参数（$m_p=1$、$m_c=10$、$L=0.5$、$g=9.81$），推导状态方程：
$$\dot{x_3} = \frac{u + \sin x_2 \cdot (0.5x_4^2) - 9.81\cos x_2}{10 + (\sin x_2)^2}$$
$$\dot{x_4} = \frac{u\cos x_2 + 0.5x_4^2 \cdot \cos x_2 \sin x_2 - 107.9\sin x_2}{0.5 \cdot (10 + (\sin x_2)^2)}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;线性化&lt;/strong&gt;：在平衡点 $x_0=[0,0,0,0]$ 处泰勒展开，忽略高阶项（$\sin x_2 \approx x_2$、$\cos x_2 \approx 1$），得到线性化模型：
$$\dot{x_3} \approx \frac{u - 9.81x_2}{10}$$
$$\dot{x_4} \approx \frac{u - 107.91x_2}{5}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;离散化&lt;/strong&gt;：基于离散化公式转换为离散时间模型，用于LQR设计：
$$A_d = I + AT,\quad B_d = BT$$
（$A$、$B$ 为线性化后的状态矩阵与输入矩阵，$T$ 为采样时间）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;2lqr控制器设计与实验结果&#34;&gt;（2）LQR控制器设计与实验结果
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;参数配置&lt;/strong&gt;：定义状态权重矩阵 $Q$ 与控制输入权重矩阵 $R$，平衡状态误差与控制能耗：
$$Q = \text{np.diag}([2.0, 10.0, 0.5, 1.0]),\quad R = \text{np.array}([[0.1]])$$
通过求解离散代数黎卡提方程得到最优反馈增益 $K$：
$$K = [[-4.4267, 262.3615, -12.0165, 57.0248]]$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始角2.7rad：小车从倾斜状态逐步调整，最终维持倒立摆竖直平衡，无明显持续晃动；&lt;/li&gt;
&lt;li&gt;多初始角验证：对2.6rad、2.7rad、2.9rad初始角均能实现稳定控制；&lt;/li&gt;
&lt;li&gt;不同Q/R对比：&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;配置&lt;/th&gt;
          &lt;th&gt;稳定时间&lt;/th&gt;
          &lt;th&gt;最大超调&lt;/th&gt;
          &lt;th&gt;控制能量（N²·s）&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Baseline（Q如上，R=0.1）&lt;/td&gt;
          &lt;td&gt;0.27s&lt;/td&gt;
          &lt;td&gt;5.0°&lt;/td&gt;
          &lt;td&gt;414654.0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;High Q（Q=np.diag([5.0,20.0,2.0,5.0])）&lt;/td&gt;
          &lt;td&gt;0.25s&lt;/td&gt;
          &lt;td&gt;5.8°&lt;/td&gt;
          &lt;td&gt;451955.5&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;High R（R=np.array([[1]])）&lt;/td&gt;
          &lt;td&gt;0.31s&lt;/td&gt;
          &lt;td&gt;3.3°&lt;/td&gt;
          &lt;td&gt;355800.3&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/RL/图2.png&#34; alt=&#34;Soft K-means不同聚类数重建效果&#34; style=&#34;max-width: 100%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图1：不同初始角效果&lt;/p&gt;
&lt;/div&gt;
&lt;h4 id=&#34;2-基于reinforce的倒立摆强化学习控制文档1最优控制与设计final-project&#34;&gt;2. 基于REINFORCE的倒立摆强化学习控制（文档1：《最优控制与设计》Final Project）
&lt;/h4&gt;&lt;h5 id=&#34;1算法设计与环境搭建&#34;&gt;（1）算法设计与环境搭建
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;仿真环境&lt;/strong&gt;：基于Gymnasium的CartPole-v1环境，状态空间含4个连续变量（小车位置、小车速度、摆杆角度、摆杆角速度），动作空间为2个离散动作（向左/向右施力）；中止条件：小车位置超±2.4m或摆杆角度超±12°。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;策略网络&lt;/strong&gt;：两层全连接神经网络，输入为4维状态，输出为动作概率分布（Softmax归一化），优化器选用AdamW。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;奖励函数&lt;/strong&gt;：综合5个维度设计，引导策略稳定平衡：
&lt;ul&gt;
&lt;li&gt;存活奖励：每一步固定奖励，鼓励长时间维持平衡；&lt;/li&gt;
&lt;li&gt;角度奖励：惩罚摆杆偏离竖直方向，偏移越小奖励越高；&lt;/li&gt;
&lt;li&gt;位置奖励：鼓励小车接近中心，偏离越远奖励越低；&lt;/li&gt;
&lt;li&gt;速度惩罚：限制小车水平速度与摆杆角速度，避免剧烈运动；&lt;/li&gt;
&lt;li&gt;综合奖励：上述子项加权组合，以存活、角度、位置奖励为主导。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;2训练流程与结果&#34;&gt;（2）训练流程与结果
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;训练流程&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;环境重置：每个回合初始状态含微小扰动；&lt;/li&gt;
&lt;li&gt;轨迹采样：智能体按策略与环境交互，记录状态、动作对数概率、即时奖励；&lt;/li&gt;
&lt;li&gt;回报计算：计算累计折扣回报 $G_t = \sum_{k=t}^T \gamma^{k-t} r_k$（$\gamma$ 为折扣因子）；&lt;/li&gt;
&lt;li&gt;策略更新：通过梯度上升最大化累计回报，每个回合结束后更新一次参数。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实验结果&lt;/strong&gt;：训练2325轮后，策略可实现倒立摆在微扰下长时间平衡，鲁棒性良好，无早期崩溃现象。&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/RL/图3.png&#34; alt=&#34;Soft K-means不同聚类数重建效果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图2：倒立摆REINFORCE训练奖励曲线&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/RL/图1.png&#34; alt=&#34;Soft K-means不同聚类数重建效果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图3：mujoco中仿真效果&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&#34;任务二双足机器人ppo强化学习控制文档1最优控制与设计final-project&#34;&gt;任务二：双足机器人PPO强化学习控制（文档1：《最优控制与设计》Final Project）
&lt;/h3&gt;&lt;h4 id=&#34;1-系统架构与核心模块&#34;&gt;1. 系统架构与核心模块
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;仿真平台&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;Isaac Gym：GPU加速物理仿真与图形渲染，支持上千个独立环境并行训练，提升采样效率；支持物理域随机化（摩擦系数、质量、重心位置随机扰动），增强策略鲁棒性；&lt;/li&gt;
&lt;li&gt;MuJoCo：高精度物理引擎，用于Sim-to-Sim迁移验证（Isaac Gym训练的策略导出为ONNX格式，部署至MuJoCo验证）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PPO训练框架核心模块&lt;/strong&gt;：&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;模块&lt;/th&gt;
          &lt;th&gt;功能描述&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;train.py&lt;/td&gt;
          &lt;td&gt;训练入口，调用task_registry创建环境（env）与PPO训练器（ppo_runner），启动训练（learn方法）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;task_registry&lt;/td&gt;
          &lt;td&gt;含make_env（创建环境与env_cfg）、make_alg_runner（创建PPO算法训练器）、register（读取地形/机器人/算法参数）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;terrain.py&lt;/td&gt;
          &lt;td&gt;地形生成：__init__初始化地形参数、curiculum调用make_terrain生成地形、make_alg_runner调用Isaac Gym的terrain_utils生成地形&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;pointfoot_rough_config.py&lt;/td&gt;
          &lt;td&gt;配置类：LeggedRobotCfg（环境参数：num_envs、地形类型、指令参数、奖励权重等）；LeggedRobotCfgPPO（PPO参数：Actor/Critic隐藏层维度（512,256,128）、ELU激活函数、训练周期等）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;2-分层奖励函数设计&#34;&gt;2. 分层奖励函数设计
&lt;/h4&gt;&lt;p&gt;针对机器人平衡、步态、指令响应需求，设计多维度奖励函数，各类型详细说明如下：&lt;/p&gt;
&lt;h3 id=&#34;1-姿态控制奖励&#34;&gt;1. 姿态控制奖励
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：维持躯干水平，避免前倾/后仰/侧倾&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现逻辑与公式&lt;/strong&gt;：通过惩罚重力向量在XY平面的投影实现，投影越小说明躯干越接近水平，奖励越高，公式如下：
$$\text{reward_orientation} = \sum \text{torch.square}(\text{projected_gravity}[:,:2])$$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-垂直速度惩罚&#34;&gt;2. 垂直速度惩罚
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：抑制竖直方向大幅运动，稳定机器人重心&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现逻辑与公式&lt;/strong&gt;：直接惩罚机身Z轴方向的速度，避免上下剧烈晃动，公式如下：
$$\text{reward_lin_vel_z} = \text{torch.square}(\text{base_lin_vel}[:,2])$$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-脚部离地时间奖励&#34;&gt;3. 脚部离地时间奖励
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：打破小碎步步态，引导机器人生成自然、稳定的行走节奏&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现逻辑&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;记录脚部接触状态（定义&lt;code&gt;contact = 接触力&amp;gt;1.0&lt;/code&gt;，接触力大于1.0时判定为着地，否则为离地）；&lt;/li&gt;
&lt;li&gt;设定目标离地时间区间：0.3~0.6s（最优目标值0.5s），计算实际离地时间与目标值的偏差，超出区间则施加惩罚；&lt;/li&gt;
&lt;li&gt;奖励仅在有速度指令时生效（零指令静止状态下不触发），避免干扰静止平衡。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-指令追踪奖励&#34;&gt;4. 指令追踪奖励
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：让机器人精准响应速度、方向类指令，提升运动可控性&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现逻辑与公式&lt;/strong&gt;：包含3类细分奖励，均通过指数函数惩罚误差，误差越小奖励越高：
&lt;ol&gt;
&lt;li&gt;线速度追踪奖励（针对XY平面速度指令）：
$$\text{reward_tracking_lin_vel} = \exp(-\text{lin_vel_error}/\text{tracking_sigma})$$
其中lin_vel_error$为XY平面实际速度与目标速度的误差，tracking_sigma为误差调节系数；&lt;/li&gt;
&lt;li&gt;角速度追踪奖励（针对Yaw轴转向指令）：
$$\text{reward_tracking_ang_vel} = \exp(-\text{ang_vel_error}/\text{tracking_sigma})$$
其中ang_vel_error为Yaw轴实际角速度与目标角速度的误差；&lt;/li&gt;
&lt;li&gt;航向角追踪奖励（针对朝向指令）：
$$\text{reward_heading_tracking} = \exp(-\text{heading_error}^2/\text{tracking_sigma})$$
其中heading_error为实际朝向与目标朝向的偏差。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-静止保持奖励&#34;&gt;5. 静止保持奖励
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：零指令时让机器人稳定站立，避免无意义滑动或姿态偏移&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现逻辑与公式&lt;/strong&gt;：通过双重惩罚引导静止状态，公式如下：
&lt;ol&gt;
&lt;li&gt;姿态误差计算：惩罚关节姿态偏离默认初始值：
$$\text{pose_error} = \sum \text{torch.square}(\text{dof_pos}-\text{default_dof_pos})$$&lt;/li&gt;
&lt;li&gt;运动误差计算：惩罚机身非必要的线速度和角速度：
$$\text{vel_error} = \sum \text{torch.square}(\text{base_lin_vel}) + \sum \text{torch.square}(\text{base_ang_vel})$$&lt;/li&gt;
&lt;li&gt;综合奖励：仅在指令速度接近0时生效，误差越小奖励越高：
$$\text{reward_stand_still} = \exp(-(\text{pose_error} + 0.5\cdot\text{vel_error})) \cdot (\text{指令速度接近0})$$&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-碰撞关节极限惩罚&#34;&gt;6. 碰撞/关节极限惩罚
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心作用&lt;/strong&gt;：避免机器人出现碰撞、关节超程等异常动作，保护仿真模型&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现逻辑&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;碰撞惩罚：检测到机器人与环境或自身碰撞时，施加固定惩罚值-3.0；&lt;/li&gt;
&lt;li&gt;关节极限惩罚：当关节角度接近物理极限（reward_dof_pos_limits）、关节速度接近最大阈值（eward_dof_vel_limits）时，施加梯度式惩罚（偏差越大惩罚越强）。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/RL/图4.png&#34; alt=&#34;Soft K-means不同聚类数重建效果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图4：相关的奖励函数&lt;/p&gt;
&lt;/div&gt;
&lt;h4 id=&#34;3-三级训练链路构建解决训练发散与步态问题&#34;&gt;3. 三级训练链路构建（解决训练发散与步态问题）
&lt;/h4&gt;&lt;p&gt;采用循序渐进策略，避免高维系统训练崩溃，具体流程如下：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;训练阶段&lt;/th&gt;
          &lt;th&gt;核心目标&lt;/th&gt;
          &lt;th&gt;关键操作与优化效果&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;第一阶段：平地平衡训练&lt;/td&gt;
          &lt;td&gt;实现稳定站立与基础移动，解决5000轮策略崩溃&lt;/td&gt;
          &lt;td&gt;操作：仅平地环境，无扰动；引入姿态控制奖励、关节极限惩罚；&lt;br&gt;效果：训练崩溃节点从5000轮延后至55000轮，躯干保持水平，减少倒地&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;第二阶段：步态与指令训练&lt;/td&gt;
          &lt;td&gt;生成自然步态，提升指令响应精度，解决小碎步&lt;/td&gt;
          &lt;td&gt;操作：① 强化脚部离地时间奖励；② 调整惩罚参数（action rate惩罚从-0.05降至-0.01，碰撞惩罚从-100降至-3.0）；③ 加入指令追踪奖励；&lt;br&gt;效果：步幅增大，左右脚交替规律，指令响应误差降低&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;第三阶段：抗扰与复杂地形训练&lt;/td&gt;
          &lt;td&gt;提升抗扰动能力与地形适配性&lt;/td&gt;
          &lt;td&gt;操作：① 开启随机推力扰动；② 启用地形课程学习（mesh_type设为trimesh，curriculum=True，从缓坡/简单非平整地形逐步升级至复杂地形）；&lt;br&gt;效果：扰动下1.2~2.0s恢复平衡，斜坡/非平整地形行走成功率超88%&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/RL/图5.png&#34; alt=&#34;Soft K-means不同聚类数重建效果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图5：刚开始训练失败部分&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/RL/fengmian.png&#34; alt=&#34;Soft K-means不同聚类数重建效果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图6：后续训练效果较好部分&lt;/p&gt;
&lt;/div&gt;
&lt;h4 id=&#34;4-关键问题解决与实验结果&#34;&gt;4. 关键问题解决与实验结果
&lt;/h4&gt;&lt;h5 id=&#34;1核心问题与解决方案&#34;&gt;（1）核心问题与解决方案
&lt;/h5&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;核心问题&lt;/th&gt;
          &lt;th&gt;产生原因&lt;/th&gt;
          &lt;th&gt;解决方案&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;PPO默认训练5000轮后策略崩溃&lt;/td&gt;
          &lt;td&gt;原始奖励仅含生存/速度追踪，无姿态约束，策略过度追求“不倒地”而非“正常行走”&lt;/td&gt;
          &lt;td&gt;引入姿态控制奖励（重力投影惩罚）、关节角度/速度极限惩罚，增强姿态稳定性&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;小碎步步态&lt;/td&gt;
          &lt;td&gt;action rate惩罚过强（-0.05），机器人不敢抬腿；无步态节奏引导&lt;/td&gt;
          &lt;td&gt;削弱action rate惩罚至-0.01；加入脚部离地时间奖励（0.3~0.6s目标区间）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;零指令下滑动&lt;/td&gt;
          &lt;td&gt;无静止状态专属奖励，策略无“保持静止”引导&lt;/td&gt;
          &lt;td&gt;新增静止保持奖励，显式惩罚姿态偏离与非必要运动&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Sim-to-Sim迁移无指令响应&lt;/td&gt;
          &lt;td&gt;训练无明确指令追踪奖励，策略未学习“响应命令”&lt;/td&gt;
          &lt;td&gt;加入线速度/角速度/航向角追踪奖励，引导策略匹配目标指令&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/RL/图6.png&#34; alt=&#34;Soft K-means不同聚类数重建效果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图6：mujoco仿真中较好的步态&lt;/p&gt;
&lt;/div&gt;
&lt;h5 id=&#34;2实验结果&#34;&gt;（2）实验结果
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;平地行走&lt;/strong&gt;：步态自然（左右脚交替，离地时间0.4~0.6s），指令响应误差&amp;lt;5%，无倒地现象；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;抗扰动能力&lt;/strong&gt;：随机推力扰动下，1.2~2.0s恢复平衡，生存奖励稳定；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;复杂地形适配&lt;/strong&gt;：&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;地形类型&lt;/th&gt;
          &lt;th&gt;行走成功率&lt;/th&gt;
          &lt;th&gt;姿态波动幅度&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;平坦地形（无扰动）&lt;/td&gt;
          &lt;td&gt;100%&lt;/td&gt;
          &lt;td&gt;＜5°&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;非平整地形（trimesh）&lt;/td&gt;
          &lt;td&gt;90%&lt;/td&gt;
          &lt;td&gt;＜8°&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;斜坡（缓坡）&lt;/td&gt;
          &lt;td&gt;92%&lt;/td&gt;
          &lt;td&gt;＜8°&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;平地+随机扰动&lt;/td&gt;
          &lt;td&gt;95%&lt;/td&gt;
          &lt;td&gt;＜7°&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;https://sxttrt.github.io/RL/%e5%8f%8c%e8%b6%b3%e6%9c%ba%e5%99%a8%e4%ba%ba%e5%a4%8d%e6%9d%82%e5%9c%b0%e5%bd%a2%e4%bb%bf%e7%9c%9f%e5%9b%be.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;双足机器人复杂地形行走仿真效果&#34;
	
	
&gt;&lt;br&gt;
&lt;em&gt;图4：双足机器人在平坦地形、非平整地形、斜坡的行走仿真效果（基于文档1）&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;四项目成果与附件&#34;&gt;四、项目成果与附件
&lt;/h2&gt;&lt;h3 id=&#34;1-仿真动态素材&#34;&gt;1. 仿真动态素材
&lt;/h3&gt;&lt;h4 id=&#34;11-倒立摆控制仿真素材&#34;&gt;1.1 倒立摆控制仿真素材
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;LQR控制：含2.6rad、2.7rad、2.9rad初始角稳定控制GIF，展示从小车倾斜到平衡的动态过程；&lt;/li&gt;
&lt;li&gt;REINFORCE控制：含训练2325轮后微扰下长时间平衡GIF，展示摆杆维持竖直的稳定状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下载链接：&lt;a class=&#34;link&#34; href=&#34;https://sxttrt.github.io/RL/%e5%80%92%e7%ab%8b%e6%91%86%e4%bb%bf%e7%9c%9fGIF%e5%90%88%e9%9b%86.zip&#34; &gt;倒立摆LQR+REINFORCE仿真GIF合集.zip&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;12-双足机器人行走仿真素材&#34;&gt;1.2 双足机器人行走仿真素材
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;平地行走：展示自然步态（左右脚交替、无小碎步）；&lt;/li&gt;
&lt;li&gt;抗扰动行走：展示随机推力下的平衡恢复过程；&lt;/li&gt;
&lt;li&gt;复杂地形行走：展示非平整地形、斜坡的适配行走。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下载链接：&lt;a class=&#34;link&#34; href=&#34;https://sxttrt.github.io/RL/%e5%8f%8c%e8%b6%b3%e6%9c%ba%e5%99%a8%e4%ba%ba%e4%bb%bf%e7%9c%9fGIF%e5%90%88%e9%9b%86.zip&#34; &gt;双足机器人多场景仿真GIF合集.zip&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-核心探索结论&#34;&gt;2. 核心探索结论
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;系统类型&lt;/th&gt;
          &lt;th&gt;关键结论&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;倒立摆LQR控制&lt;/td&gt;
          &lt;td&gt;1. Q/R矩阵权重影响控制效果：High Q（大状态权重）响应更快但超调更大、能耗更高；High R（大控制权重）响应更慢但超调更小、能耗更低；&lt;br&gt;2. 离散化模型是LQR适用于数字控制的关键，需基于线性化模型推导&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;倒立摆REINFORCE控制&lt;/td&gt;
          &lt;td&gt;1. 多维度奖励函数（含存活、角度、位置、速度）是避免策略“钻空子”（如仅追求存活不保持平衡）的核心；&lt;br&gt;2. 训练2325轮后策略收敛，可实现微扰下长时间平衡，验证策略梯度算法对低维非线性系统的适配性&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;双足机器人PPO控制&lt;/td&gt;
          &lt;td&gt;1. 三级训练链路（平衡→步态→复杂地形）是避免高维系统训练发散的关键，直接训练复杂地形会导致策略崩溃；&lt;br&gt;2. 物理域随机化与Sim-to-Sim迁移可显著提升策略泛化能力，适配不同仿真环境差异；&lt;br&gt;3. 脚部离地时间控制在0.4~0.6s时，步态最接近自然行走，能耗与稳定性平衡最优&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;3-附件文件&#34;&gt;3. 附件文件
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;项目源码仓库&lt;/strong&gt;：含所有核心模块代码（train.py、task_registry.py、terrain.py、pointfoot_rough_config.py等），详见：&lt;a class=&#34;link&#34; href=&#34;https://github.com/xxx/RL-Robot-Control&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RL-Robot-Control（示例链接，需替换为实际仓库）&lt;/a&gt;；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;模型文件&lt;/strong&gt;：双足机器人PPO策略ONNX格式文件（Isaac Gym训练导出，用于MuJoCo迁移）、倒立摆REINFORCE模型权重文件；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;实验配置文件&lt;/strong&gt;：Isaac Gym/MuJoCo环境参数配置（含terrain.py参数、pointfoot_rough_config.py完整代码）；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;实验图表素材&lt;/strong&gt;：所有训练奖励曲线、LQR参数对比图、机器人步态轨迹图的原始文件。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>基于Gen3-lite机械臂的绘画机器人系统</title>
        <link>https://sxttrt.github.io/zh-cn/p/painting-robot/</link>
        <pubDate>Wed, 04 Jun 2025 00:00:00 +0000</pubDate>
        
        <guid>https://sxttrt.github.io/zh-cn/p/painting-robot/</guid>
        <description>&lt;img src="https://sxttrt.github.io/gen3/fengmian.png" alt="Featured image of post 基于Gen3-lite机械臂的绘画机器人系统" /&gt;&lt;!-- MathJax配置 --&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;script&gt;
MathJax.config = {
  tex: {
    inlineMath: [[&#39;$&#39;, &#39;$&#39;], [&#39;\\(&#39;, &#39;\\)&#39;]],
    displayMath: [[&#39;$$&#39;, &#39;$$&#39;], [&#39;\\[&#39;, &#39;\\]&#39;]],
    processEscapes: true
  },
  svg: {
    fontCache: &#39;global&#39;
  }
};
&lt;/script&gt;
&lt;h2 id=&#34;一项目核心信息&#34;&gt;一、项目核心信息
&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;信息类别&lt;/th&gt;
          &lt;th&gt;具体内容&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;项目名称&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;基于Kinova Gen3-lite机械臂的绘画机器人系统构建&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心成员&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;李育昆、刘承韬、王博彬&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;项目周期&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;2025年3月-2025年6月&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心任务&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;1. 图像扫描：基于OpenCV完成摄像头采集、预处理、边缘检测与轮廓提取&lt;br&gt;2. 轨迹规划：图像二值化、骨架提取、路径合并简化、坐标归一化&lt;br&gt;3. 机械臂控制：ROS框架下力控轨迹跟踪、坐标转换、抬笔/落笔动作模拟&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;关键工具&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Python、OpenCV（图像处理）、NumPy（数值计算）、ROS（机器人操作系统）、Kinova Gen3-lite机械臂、Kortex SDK（机械臂控制接口）、skimage（骨架提取）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;二项目背景与目标&#34;&gt;二、项目背景与目标
&lt;/h2&gt;&lt;h3 id=&#34;1-项目背景&#34;&gt;1. 项目背景
&lt;/h3&gt;&lt;p&gt;传统人工绘画依赖经验与熟练度，复刻复杂线描图案时易出现偏差，且批量复刻效率极低；而Kinova Gen3-lite机械臂作为轻量级协作机械臂，具备±0.1mm的重复定位精度，结合计算机视觉与机器人控制技术，可实现“视觉感知→路径规划→机械执行”的全自动化闭环。&lt;/p&gt;
&lt;p&gt;本项目针对教育演示、小型创意工坊等轻量化场景，规避复杂的工业级视觉标定与力控方案，通过开源工具链（OpenCV+ROS）实现低成本、易部署的机械臂绘画系统，解决“图像如何转化为机械臂可执行轨迹”“无专用力传感器时如何维持画笔与纸张稳定接触”两大核心问题。&lt;/p&gt;
&lt;h3 id=&#34;2-核心目标&#34;&gt;2. 核心目标
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图像处理目标&lt;/strong&gt;：针对不同光照、不同复杂度的简单线描图像（如动物简笔画、几何图案），实现轮廓精准提取，通过形态学操作增强边缘连续性，去除纸张纹理、拍摄噪声等干扰因素；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;路径规划目标&lt;/strong&gt;：将图像轮廓转化为连续、无冗余的机械臂运动轨迹，通过抬笔/落笔节点标记，减少机械臂无效动作，确保绘画流畅性；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;机械臂控制目标&lt;/strong&gt;：基于雅可比转置法实现末端执行器力估计，通过PD控制器维持13N的稳定接触力，适配不同厚度纸张的绘画需求；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;系统集成目标&lt;/strong&gt;：完成“图像扫描→轨迹生成→机械绘画”全流程自动化，单幅200个路径点以内的线描图绘画耗时≤5分钟，复刻偏差≤1mm。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三核心任务实现&#34;&gt;三、核心任务实现
&lt;/h2&gt;&lt;h3 id=&#34;任务一图像扫描与预处理基于opencv&#34;&gt;任务一：图像扫描与预处理（基于OpenCV）
&lt;/h3&gt;&lt;h4 id=&#34;1-完整处理流程&#34;&gt;1. 完整处理流程
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;硬件与参数初始化&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;摄像头适配：调用&lt;code&gt;cv2.VideoCapture(6)&lt;/code&gt;启用工业摄像头（设备号根据实际硬件调整），设置图像分辨率为480×640（兼顾处理效率与细节保留）；&lt;/li&gt;
&lt;li&gt;参数校准：通过&lt;code&gt;cap.set(10, 160)&lt;/code&gt;调整摄像头亮度，适配室内常规光照环境；&lt;/li&gt;
&lt;li&gt;工具函数准备：自定义&lt;code&gt;stackImages&lt;/code&gt;函数实现多图拼接可视化，&lt;code&gt;valTrackbars&lt;/code&gt;函数创建阈值调节轨迹栏，便于实时调整边缘检测参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;图像优化处理&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;灰度转换：将彩色图像转为灰度图（&lt;code&gt;cv2.COLOR_BGR2GRAY&lt;/code&gt;），减少3/4的计算量，聚焦线条轮廓特征；&lt;/li&gt;
&lt;li&gt;高斯降噪：采用5×5卷积核执行高斯模糊（&lt;code&gt;cv2.GaussianBlur(imgGray, (5, 5), 1)&lt;/code&gt;），平滑图像并降低椒盐噪声、拍摄抖动带来的干扰；&lt;/li&gt;
&lt;li&gt;边缘检测：通过轨迹栏实时调整Canny算法的高低阈值，提取图像边缘轮廓；&lt;/li&gt;
&lt;li&gt;形态学增强：用5×5矩形核执行膨胀操作（&lt;code&gt;cv2.dilate&lt;/code&gt;）连接断开的边缘线条，再执行腐蚀操作（&lt;code&gt;cv2.erode&lt;/code&gt;）去除小面积噪声点，强化轮廓完整性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;轮廓提取与可视化&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;轮廓检测：采用&lt;code&gt;cv2.findContours&lt;/code&gt;函数，设置&lt;code&gt;RETR_EXTERNAL&lt;/code&gt;参数仅提取最外层轮廓，&lt;code&gt;CHAIN_APPROX_SIMPLE&lt;/code&gt;参数压缩冗余轮廓点，减少后续轨迹计算量；&lt;/li&gt;
&lt;li&gt;结果展示：将原始图、灰度图、阈值图、轮廓图通过&lt;code&gt;stackImages&lt;/code&gt;函数拼接为2×2阵列，实时显示处理效果，便于参数调试。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;交互与保存&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;触发机制：按下键盘&lt;code&gt;s&lt;/code&gt;键保存当前扫描的处理结果，文件名格式为&lt;code&gt;scan_result_计数器.jpg&lt;/code&gt;（计数器自增），确保文件唯一性；&lt;/li&gt;
&lt;li&gt;反馈提示：在拼接图像上绘制绿色背景的提示框，显示红色“Scan Saved”文字，持续300毫秒后恢复原图显示，提升操作交互性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;2-处理效果展示&#34;&gt;2. 处理效果展示
&lt;/h4&gt;&lt;div style=&#34;flex: 1 1 30%; text-align: center;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/gen3/图1.png&#34; alt=&#34;原始拍摄图&#34; style=&#34;max-width: 100%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666; margin-top: 8px;&#34;&gt;图1：3种不同图片的处理效果&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&#34;任务二轨迹规划图像机械路径&#34;&gt;任务二：轨迹规划（图像→机械路径）
&lt;/h3&gt;&lt;h4 id=&#34;1-核心实现步骤&#34;&gt;1. 核心实现步骤
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;图像二值化与边界处理&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;阈值分割：将预处理后的灰度图通过&lt;code&gt;cv2.threshold&lt;/code&gt;转为黑白二值图，设置线条（前景）为白色、背景为黑色，简化后续骨架提取逻辑；&lt;/li&gt;
&lt;li&gt;边界补充：通过&lt;code&gt;cv2.copyMakeBorder&lt;/code&gt;在图像四周添加5像素白色边框，避免图像边缘的线条在骨架提取时被截断，保证路径完整性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;骨架提取与断点修复&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中心线提取：调用&lt;code&gt;skimage.morphology.skeletonize&lt;/code&gt;函数将宽线条细化为单像素中心线，降低机械臂轨迹复杂度；&lt;/li&gt;
&lt;li&gt;断点连接：遍历骨架图像像素，检测8邻域内的对称断点（如上下/左右成对的孤立点），自动填充断点，提升路径连续性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;路径提取与优化&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;端点检测：遍历骨架像素，识别仅含1个邻域像素的端点，作为轨迹追踪的起始点；&lt;/li&gt;
&lt;li&gt;轨迹追踪：从端点出发，沿8邻域遍历有效骨架像素，提取完整的线条路径；&lt;/li&gt;
&lt;li&gt;闭环补充：扫描未被访问的骨架像素，补充圆形、多边形等闭环路径，避免遗漏内部轮廓；&lt;/li&gt;
&lt;li&gt;路径合并：计算相邻路径端点的欧氏距离，若小于10像素则拼接为长路径，减少机械臂抬笔次数；&lt;/li&gt;
&lt;li&gt;路径简化：调用&lt;code&gt;cv2.approxPolyDP&lt;/code&gt;函数，设置合适的epsilon参数（2像素），保留路径关键转折点，丢弃冗余中间点，路径点数量平均减少60%以上。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;坐标归一化与文件输出&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;空间映射：将像素坐标（x,y）按图像宽高映射至[0,1]区间，消除不同图像尺寸的影响，适配机械臂0.5×0.5m的工作空间；&lt;/li&gt;
&lt;li&gt;格式定义：将归一化后的坐标写入文本文件，路径间用“BREAK”字符串标记（表示机械臂抬笔动作），便于后续控制程序解析。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;2-轨迹规划效果展示&#34;&gt;2. 轨迹规划效果展示
&lt;/h4&gt;&lt;div style=&#34;display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; margin: 20px 0;&#34;&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/gen3/图2.png&#34; alt=&#34;骨架提取效果&#34; style=&#34;max-width: 100%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666; margin-top: 8px;&#34;&gt;图2：骨架提取后的单像素中心线&lt;/p&gt;
  &lt;/div&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/gen3/图3.png&#34; alt=&#34;优化后路径&#34; style=&#34;max-width: 100%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666; margin-top: 8px;&#34;&gt;图3：合并简化后的机械臂执行路径&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;任务三机械臂控制基于ros与kortex-sdk&#34;&gt;任务三：机械臂控制（基于ROS与Kortex SDK）
&lt;/h3&gt;&lt;h4 id=&#34;1-力控核心实现&#34;&gt;1. 力控核心实现
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;末端力估计（无专用力传感器）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原理：基于机器人学雅可比转置关系，通过关节力矩测量值估计末端执行器的力/力矩，核心公式：
$$F_{ee} = J^T \tau$$
其中$F_{ee} \in \mathbb{R}^6$为末端执行器估计力/力矩，$J \in \mathbb{R}^{6×6}$为Gen3-lite机械臂雅可比矩阵，$\tau \in \mathbb{R}^6$为关节力矩测量值；&lt;/li&gt;
&lt;li&gt;雅可比计算：基于Gen3-lite的DH参数，通过连杆变换矩阵与叉积公式求解雅可比矩阵，实时发布至ROS话题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PD力控轨迹跟踪&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;控制目标：维持画笔与纸张的Z轴接触力稳定在13N（适配普通A4纸的承压能力）；&lt;/li&gt;
&lt;li&gt;控制律设计：通过Z轴位置补偿消除力误差，公式如下：
$$\Delta z = K_p e_f + K_d \dot{e}&lt;em&gt;f$$
其中$e_f = F&lt;/em&gt;{desired} - F_z$（力误差），$K_p=0.005$（比例增益），$K_d=0.001$（微分增益）；&lt;/li&gt;
&lt;li&gt;鲁棒性设计：
&lt;ul&gt;
&lt;li&gt;接触检测：仅当$|F_z|&amp;gt;1N$时激活力控制器，避免自由空间内的控制震荡；&lt;/li&gt;
&lt;li&gt;饱和限制：单周期Z轴调整量不超过0.01m，确保机械臂运动平滑；&lt;/li&gt;
&lt;li&gt;稳态补偿：累积位置偏移量，消除静态力误差，适配纸张厚度变化。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;2-路径执行与ros节点设计&#34;&gt;2. 路径执行与ROS节点设计
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;坐标映射&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将归一化坐标（[0,1]）通过缩放（$x=(x_{norm}+0.1)/2.5$，$y=(y_{norm}+0.1)/2.5$）与旋转（$\phi=-50°$），映射至机械臂基坐标系，适配画笔安装位置；&lt;/li&gt;
&lt;li&gt;动作定义：正常路径点执行时，Z轴标称高度为0.028m（落笔状态），检测到“BREAK”标记时，抬笔至0.15m安全高度移动。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ROS节点架构&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jacobian节点（jacobian.py）：订阅关节状态话题，实时计算并发布雅可比矩阵、末端力估计值；&lt;/li&gt;
&lt;li&gt;Painting Control节点（painting.cpp）：订阅力反馈话题，解析路径文件，发布笛卡尔运动指令，控制夹爪抬笔/落笔动作；&lt;/li&gt;
&lt;li&gt;执行流程：初始化→归位至安全起点→移动取笔→逐点执行路径（力控补偿）→归位放笔。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;四项目成果与演示&#34;&gt;四、项目成果与演示
&lt;/h2&gt;&lt;h3 id=&#34;1-绘画效果对比&#34;&gt;1. 绘画效果对比
&lt;/h3&gt;&lt;div style=&#34;display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; margin: 20px 0;&#34;&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/gen3/图4.png&#34; alt=&#34;鲸鱼原始图&#34; style=&#34;max-width: 100%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666; margin-top: 8px;&#34;&gt;图4：鲸鱼简笔画原始输入图&lt;/p&gt;
  &lt;/div&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/gen3/图5.png&#34; alt=&#34;鲸鱼绘画成果&#34; style=&#34;max-width: 100%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666; margin-top: 8px;&#34;&gt;图5：机械臂绘画成果图&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;2-论文预览与下载&#34;&gt;2. 论文预览与下载
&lt;/h3&gt;&lt;iframe src=&#34;https://sxttrt.github.io/gen3/The Final Project.pdf&#34; width=&#34;100%&#34; height=&#34;700&#34; style=&#34;border: 1px solid #e0e0e0; border-radius: 6px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);&#34; title=&#34;机械臂绘画论文&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;若浏览器加载缓慢或无法预览，可直接下载：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sxttrt.github.io/gen3/The Final Project.pdf&#34; target=&#34;_blank&#34;&gt;The Final Project.pdf 下载链接&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-核心结论与优化方向&#34;&gt;3. 核心结论与优化方向
&lt;/h3&gt;&lt;h4 id=&#34;1-核心结论&#34;&gt;1. 核心结论
&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;技术维度&lt;/th&gt;
          &lt;th&gt;关键结论&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;图像预处理&lt;/td&gt;
          &lt;td&gt;高斯模糊（5×5核）+膨胀-腐蚀（迭代2/1次）的组合策略，可有效去除90%以上的拍摄噪声，边缘提取准确率≥95%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;路径规划&lt;/td&gt;
          &lt;td&gt;骨架提取+端点合并+approxPolyDP简化的流程，可将路径点数量减少60%-70%，机械臂执行效率提升50%以上&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;力控控制&lt;/td&gt;
          &lt;td&gt;基于雅可比转置的力估计方法，在无专用力传感器时，接触力波动可控制在±1.5N以内，满足绘画稳定性要求&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;系统整体&lt;/td&gt;
          &lt;td&gt;单幅200点以内的线描图，全流程自动化执行耗时3-5分钟，复刻偏差≤1mm，适配A4纸范围内的绘画需求&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;2-后续优化方向&#34;&gt;2. 后续优化方向
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;图像适配：增加透视变换校正功能，适配非正拍的图像输入场景；&lt;/li&gt;
&lt;li&gt;路径优化：引入贝塞尔曲线平滑路径，减少机械臂运动拐点处的抖动；&lt;/li&gt;
&lt;li&gt;力控升级：融合视觉反馈（画笔接触状态）与力反馈，提升复杂曲面绘画的稳定性；&lt;/li&gt;
&lt;li&gt;交互拓展：开发Web端控制界面，支持图像上传、路径预览、绘画进度实时显示。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>声控协作式机器人系统设计与实现</title>
        <link>https://sxttrt.github.io/zh-cn/p/ur-robot/</link>
        <pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate>
        
        <guid>https://sxttrt.github.io/zh-cn/p/ur-robot/</guid>
        <description>&lt;img src="https://sxttrt.github.io/UR-Robot/fengmian.png" alt="Featured image of post 声控协作式机器人系统设计与实现" /&gt;&lt;h2 id=&#34;一项目核心信息&#34;&gt;一、项目核心信息
&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;信息类别&lt;/th&gt;
          &lt;th&gt;具体内容&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;项目名称&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;声控协作式机器人系统设计与实现&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;负责角色&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;项目负责人&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;项目周期&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;2024年10月-2024年12月&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心成员&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;刘承韬（本人）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;指导教师&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;熊异（智能控制科学创新实践II课程指导）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心任务&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;1. DTW算法语音识别（工具关键词识别）&lt;br&gt;2. YOLOv8工具物体检测（5类工具）&lt;br&gt;3. GRCNN平面抓取点生成&lt;br&gt;4. UR机器人+夹爪控制（ur-rtde/minimalmodbus）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;关键工具&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Python（核心逻辑）、OpenCV（图像处理）、YOLOv8（目标检测）、GRCNN（抓取规划）、ur-rtde（机器人控制）、MinimalModbus（夹爪控制）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;项目产出&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;1. 可运行声控抓取系统&lt;br&gt;2. 工具识别模型（YOLOv8权重）&lt;br&gt;3. 实物抓取演示视频&lt;br&gt;4. 完整项目代码（含UI界面）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;二项目背景与目标&#34;&gt;二、项目背景与目标
&lt;/h2&gt;&lt;h3 id=&#34;1-项目背景&#34;&gt;1. 项目背景
&lt;/h3&gt;&lt;p&gt;在工业装配、仓储分拣等场景中，传统机器人需手动设定坐标，操作繁琐且灵活性低。声控作为自然的人机交互方式，可实现“语音指令→自动识别→精准抓取”的全流程自动化，既能提升生产效率，又能降低工人操作门槛。本项目以“工具抓取”为核心场景，融合语音识别（DTW）、计算机视觉（YOLOv8/GRCNN）与机器人控制技术，开发适用于工业场景的轻量级声控协作系统，避免深度学习黑箱依赖，兼顾实时性与可控性。&lt;/p&gt;
&lt;h3 id=&#34;2-核心目标&#34;&gt;2. 核心目标
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;语音识别：实现“锤子、扳手、螺丝刀、钳子、卷尺”5类工具关键词识别，单词识别准确率≥90%，支持短句关键词提取（关键词位于句首时准确率≥85%）。&lt;/li&gt;
&lt;li&gt;物体识别：YOLOv8模型对5类工具的检测精度（mAP50）≥93%，泛化性覆盖不同光照、摆放角度的实物场景。&lt;/li&gt;
&lt;li&gt;抓取控制：GRCNN生成有效抓取点准确率≥90%，UR机器人抓取成功率≥85%，夹爪可根据工具材质自适应调整力度（如卷尺40%力度、金属工具80%力度）。&lt;/li&gt;
&lt;li&gt;交互体验：开发可视化UI界面，支持“语音录入→图像识别→抓取执行”一键操作，配套实物抓取演示视频。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三核心任务实现&#34;&gt;三、核心任务实现
&lt;/h2&gt;&lt;h3 id=&#34;任务一基于dtw算法的语音识别模块&#34;&gt;任务一：基于DTW算法的语音识别模块
&lt;/h3&gt;&lt;h4 id=&#34;1-算法流程与预处理&#34;&gt;1. 算法流程与预处理
&lt;/h4&gt;&lt;p&gt;采用“模板录制→信号预处理→DTW匹配”三步流程，核心是通过动态时间规整解决语音信号长度不一致问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模板录制&lt;/strong&gt;：对5类工具关键词，每种以不同声调和语速录制6条音频（采样率16000Hz、单声道、2字节采样），生成30条模板音频（如图1）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;信号预处理&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;分帧（帧长20ms、帧移10ms）、预加重（提升高频信号）；&lt;/li&gt;
&lt;li&gt;双门限法端点检测，分离语音有效部分与静音；&lt;/li&gt;
&lt;li&gt;提取MFCC特征（13维系数），将音频信号转化为特征向量（如图2）。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DTW匹配&lt;/strong&gt;：实时录音（2.5秒时长、CHUNK=1024采样块），提取MFCC后与模板特征计算欧氏距离，选择距离最小的模板作为识别结果（如“锤子”匹配距离≈7585，如图3）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-关键图片与识别结果&#34;&gt;2. 关键图片与识别结果
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;预处理与模板存储&lt;/strong&gt;：&lt;/p&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/UR-Robot/图1.png&#34; alt=&#34;音频模板与MFCC特征文件&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图1：音频模板（上）与MFCC特征文件（下）&lt;/p&gt;
  &lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;识别结果与分析&lt;/strong&gt;：&lt;/p&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/UR-Robot/图3.png&#34; alt=&#34;DTW匹配距离与识别结果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图3：DTW匹配距离计算（最小距离对应“锤子”，识别成功）&lt;/p&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align: center; margin: 10px 0;&#34;&gt;
  &lt;table style=&#34;max-width: 80%; margin: 0 auto; border-collapse: collapse; border: 1px solid #eee;&#34;&gt;
    &lt;tr style=&#34;background-color: #f5f5f5;&#34;&gt;
      &lt;th style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;识别类型&lt;/th&gt;
      &lt;th style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;锤子&lt;/th&gt;
      &lt;th style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;扳手&lt;/th&gt;
      &lt;th style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;螺丝刀&lt;/th&gt;
      &lt;th style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;钳子&lt;/th&gt;
      &lt;th style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;卷尺&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;单词识别（30次）&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;30/30&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;30/30&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;30/30&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;28/30&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;29/30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;短句识别（关键词句首）&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;28/30&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;29/30&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;29/30&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;-/30&lt;/td&gt;
      &lt;td style=&#34;padding: 8px; border: 1px solid #eee; text-align: center;&#34;&gt;-/30&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
  &lt;p style=&#34;font-size: 14px; color: #666; margin-top: 8px;&#34;&gt;表1：语音识别准确率统计（误差源于“钳子/卷尺”发音相似性）&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;任务二基于yolov8的工具物体识别&#34;&gt;任务二：基于YOLOv8的工具物体识别
&lt;/h3&gt;&lt;h4 id=&#34;1-模型开发与数据集优化&#34;&gt;1. 模型开发与数据集优化
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模型选择&lt;/strong&gt;：选用YOLOv8（对比YOLOv5精度提升12%、YOLOv11社区支持更成熟），聚焦5类工具（锤子、扳手、螺丝刀、钳子、卷尺）检测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据集迭代&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;初始数据集：200张图像（含椒盐噪声、旋转增强），训练100轮后mAP50=88%，但实物检测漏检率高；&lt;/li&gt;
&lt;li&gt;优化数据集：剔除卡通/手持工具图像，补充实验室实物图像（300张），采用“小模型预训练+增量训练”策略（先100轮小数据集，再分两次50轮增量训练）；&lt;/li&gt;
&lt;li&gt;知识蒸馏：用大模型（YOLOv8-L）作为教师模型，将工具特征传递给学生模型（YOLOv8-N），提升小模型泛化性。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练结果&lt;/strong&gt;：优化后模型mAP50=95.2%，各类工具检测精度均≥93%，实物场景漏检率降低至10%以下（如图4、5）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-关键图片与检测效果&#34;&gt;2. 关键图片与检测效果
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;训练损失与精度曲线&lt;/strong&gt;：&lt;/p&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/UR-Robot/图4.png&#34; alt=&#34;YOLOv8训练损失曲线&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图4：首次200轮训练损失曲线（train/val loss收敛至0.5）&lt;/p&gt;
  &lt;/div&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/UR-Robot/图5.png&#34; alt=&#34;YOLOv8验证集指标&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图5：最终验证集指标（mAP50=95.2%，precision=93.1%）&lt;/p&gt;
  &lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;实物检测效果&lt;/strong&gt;：&lt;/p&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/UR-Robot/图6.png&#34; alt=&#34;工具实物检测结果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图6：实物工具检测（标注置信度与类别，无漏检）&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;任务三grcnn抓取规划与机器人控制&#34;&gt;任务三：GRCNN抓取规划与机器人控制
&lt;/h3&gt;&lt;h4 id=&#34;1-平面抓取点生成grcnn&#34;&gt;1. 平面抓取点生成（GRCNN）
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心逻辑&lt;/strong&gt;：结合Realsense双目相机的RGB+深度信息，GRCNN生成全局抓取置信度图，再根据YOLOv8检测框裁剪局部区域，提取最优抓取点（位置、角度、宽度）：
&lt;ol&gt;
&lt;li&gt;图像预处理：裁剪YOLOv8检测框区域（置信度≥0.5），添加20px边缘避免漏裁工具；&lt;/li&gt;
&lt;li&gt;抓取参数生成：输出抓取质量图（q_img）、角度图（ang_img）、宽度图（width_img），寻找局部最大值作为最优抓取点（如图7）；&lt;/li&gt;
&lt;li&gt;适配性优化：对扁平工具（如扳手）增加深度信息权重，减少无效抓取点。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-坐标变换与机器人控制&#34;&gt;2. 坐标变换与机器人控制
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;坐标映射&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;像素→相机坐标：利用Realsense内参（fx、fy、cx、cy），结合深度值Z，通过相机投影公式计算三维坐标（如图8）；&lt;/li&gt;
&lt;li&gt;相机→机器人坐标：用5×5棋盘格标定（24个标定 points，移动步距5cm），计算手眼变换矩阵T，实现坐标转换。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;UR机器人控制&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;采用&lt;code&gt;ur-rtde&lt;/code&gt;库，通过TCP/IP协议控制机器人，用&lt;code&gt;move_L&lt;/code&gt;/&lt;code&gt;move_J&lt;/code&gt;函数实现线性/关节运动（速度=0.2m/s，加速度=0.1m/s²，误差容忍2mm/0.01rad）；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;夹爪控制&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;用&lt;code&gt;MinimalModbus&lt;/code&gt;库通过串口控制夹爪，根据识别到的不同工具，实现自适应力度：金属工具（锤子/扳手）用80%力度，塑料工具（卷尺）用40%力度，避免损坏或掉落。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-关键图片与控制效果&#34;&gt;3. 关键图片与控制效果
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GRCNN抓取点与坐标变换&lt;/strong&gt;：&lt;/p&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/UR-Robot/图7.png&#34; alt=&#34;GRCNN抓取点生成&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图7：钳子抓取点（蓝色框为最优抓取位置，角度=0.57rad）&lt;/p&gt;
  &lt;/div&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/UR-Robot/图8.png&#34; alt=&#34;相机-机器人坐标变换公式&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图8：像素坐标→机器人坐标变换公式&lt;/p&gt;
  &lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;UI界面与抓取流程&lt;/strong&gt;：&lt;/p&gt;
&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/UR-Robot/图9.png&#34; alt=&#34;系统UI界面&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图9：系统UI界面（含“语音识别、图像识别、按标签筛选、语音抓取”功能）&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;任务四实物抓取视频展示&#34;&gt;任务四：实物抓取视频展示
&lt;/h3&gt;&lt;p&gt;项目配套实物抓取演示视频，记录“语音指令→工具识别→机器人抓取”全流程，视频包含3个关键场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;场景1：语音输入“锤子”→YOLOv8检测锤子→GRCNN生成抓取点→UR机器人移动抓取；&lt;/li&gt;
&lt;li&gt;场景2：语音输入“卷尺”→夹爪自动切换40%力度→平稳抓取无损坏；&lt;/li&gt;
&lt;li&gt;场景3：多工具混合摆放→按语音标签筛选目标→精准抓取无误触。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;div&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;text-align: center; margin: 20px 0;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;video&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;80%&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;controls&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;poster&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/project/robot/video-cover.png&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/UR-Robot/video1.mp4&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;video/mp4&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   您的浏览器不支持HTML5视频播放，请下载视频查看：&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;href&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;UR-Robot/视频1.mp4&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;_blank&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;下载演示视频&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;video&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;font-size: 14px; color: #666; margin-top: 8px;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;视频1：声控机器人实物抓取演示（时长1分20秒）&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;div&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;四项目成果与附件&#34;&gt;四、项目成果与附件
&lt;/h2&gt;&lt;h3 id=&#34;核心成果&#34;&gt;核心成果
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;成果类型&lt;/th&gt;
          &lt;th&gt;具体指标&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;语音识别&lt;/td&gt;
          &lt;td&gt;单词准确率≥93%，短句（关键词句首）准确率≥85%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;物体检测&lt;/td&gt;
          &lt;td&gt;YOLOv8 模型 mAP50=95.2%，实物检测漏检率≤10%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;抓取控制&lt;/td&gt;
          &lt;td&gt;GRCNN 抓取点有效率≥80%，UR 机器人抓取成功率≥75%，夹爪力度自适应&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;系统响应&lt;/td&gt;
          &lt;td&gt;从语音指令到抓取完成≤10 秒，无人工干预&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        <item>
        <title>基于传统机器学习算法的分类与图像处理研究</title>
        <link>https://sxttrt.github.io/zh-cn/p/ai-research/</link>
        <pubDate>Sat, 30 Nov 2024 00:00:00 +0000</pubDate>
        
        <guid>https://sxttrt.github.io/zh-cn/p/ai-research/</guid>
        <description>&lt;img src="https://sxttrt.github.io/ai/fengmian.png" alt="Featured image of post 基于传统机器学习算法的分类与图像处理研究" /&gt;&lt;!-- 完整MathJax配置（加载+识别规则），复制到文章开头即可 --&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;script&gt;
// 明确MathJax的公式识别规则，避免冲突
MathJax.config = {
  tex: {
    inlineMath: [[&#39;$&#39;, &#39;$&#39;], [&#39;\\(&#39;, &#39;\\)&#39;]],  // 行内公式：$...$ 或 \(...\)
    displayMath: [[&#39;$$&#39;, &#39;$$&#39;], [&#39;\\[&#39;, &#39;\\]&#39;]],  // 行间公式：$$...$$ 或 \[...\]
    processEscapes: true,  // 允许反斜杠转义（比如 \sum、\mu 正常生效）
    processEnvironments: true  // 支持复杂公式环境（如矩阵、分段函数）
  },
  svg: {
    fontCache: &#39;global&#39;  // 缓存字体，加快渲染速度
  }
};
&lt;/script&gt;
&lt;h2 id=&#34;一项目核心信息&#34;&gt;一、项目核心信息
&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;信息类别&lt;/th&gt;
          &lt;th&gt;具体内容&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;项目名称&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;基于传统机器学习算法的分类与图像处理研究&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;负责角色&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;项目负责人&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;项目周期&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;2024年09月-2024年11月&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心成员&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;刘承韬（本人）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心任务&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;1. K-means/Soft K-means种子数据集分类（优化分裂合并策略）&lt;br&gt;2. PCA/Linear Autoencoder/Soft K-means图像重建（不同维度/聚类数对比）&lt;br&gt;3. Logistic Regression/MLP二分类（超参数调优：隐藏层/神经元/容忍度）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;关键工具&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Python（核心逻辑）、NumPy（矩阵计算）、Matplotlib（实验可视化）、Pandas（数据处理）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;二项目背景与目标&#34;&gt;二、项目背景与目标
&lt;/h2&gt;&lt;h3 id=&#34;1-项目背景&#34;&gt;1. 项目背景
&lt;/h3&gt;&lt;p&gt;深度学习虽在大规模复杂任务中表现突出，但存在参数冗余、可解释性弱、依赖高算力的局限；而传统机器学习算法（如K-means、PCA、Logistic Regression）因原理透明、轻量化、易复现，在中小规模数据场景（如种子分类、图像降维）中仍具重要研究价值。&lt;/p&gt;
&lt;p&gt;本项目以“&lt;strong&gt;探索传统算法的性能边界与参数影响规律&lt;/strong&gt;”为核心，聚焦两类典型任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分类任务&lt;/strong&gt;：包含“种子数据集聚类”（K-means/Soft K-means）与“X型分布数据二分类”（Logistic Regression/MLP），探索算法类型、超参数对分类效果的影响；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图像处理任务&lt;/strong&gt;：基于PCA、Linear Autoencoder、Soft K-means实现图像重建，探索“保留维度/聚类数”与“重建质量”的关联。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有算法均通过纯Python/NumPy实现，不依赖第三方机器学习库，旨在深入理解算法底层逻辑，并通过对比实验总结可复用的参数调优规律。&lt;/p&gt;
&lt;h3 id=&#34;2-核心目标&#34;&gt;2. 核心目标
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;聚类分类探索&lt;/strong&gt;：以种子数据集为对象，探索K-means与Soft K-means在“不同聚类数、分裂合并策略、迭代数、容忍度”下的聚类效果，对比两类算法的准确率稳定性与抗局部最优能力，总结参数对聚类性能的影响规律；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图像重建探索&lt;/strong&gt;：以WWI士兵图像为处理对象，分别用PCA、Linear Autoencoder、Soft K-means进行重建，探索“保留维度（PCA/AE）、聚类数（Soft K-means）”对图像色彩还原、细节保留的影响，明确不同算法在图像处理中的优劣场景；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;二分类探索&lt;/strong&gt;：针对X型分布的人工生成数据，对比线性模型（Logistic Regression）与非线性模型（MLP）的拟合能力，重点探索MLP中“隐藏层数量、神经元数、容忍度”对收敛速度、拟合精度的影响，明确非线性模型适配复杂数据的关键条件；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工程化支撑&lt;/strong&gt;：将所有算法模块化封装，配套实验可视化脚本（准确率曲线、重建效果对比图），确保实验过程可复现、结果可直观解读，为后续传统算法应用提供参考模板。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三核心任务实现&#34;&gt;三、核心任务实现
&lt;/h2&gt;&lt;h3 id=&#34;任务一k-means与soft-k-means聚类分类种子数据集探索&#34;&gt;任务一：K-means与Soft K-means聚类分类（种子数据集探索）
&lt;/h3&gt;&lt;h4 id=&#34;1-探索方向与算法设计&#34;&gt;1. 探索方向与算法设计
&lt;/h4&gt;&lt;p&gt;本次探索聚焦“&lt;strong&gt;算法类型（K-means/Soft K-means）、超参数（聚类数、分裂合并、迭代数、容忍度）对聚类准确率的影响&lt;/strong&gt;”，为匹配探索目标，对两类算法进行针对性设计：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;K-means设计（服务探索目标）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心逻辑：通过最小化簇内平方误差&lt;br&gt;
$$J=\sum_{i=1}^{k} \sum_{x \in C_{i}}\left| x-\mu_{i}\right| ^{2}$$&lt;br&gt;
（$C_i$为第$i$个簇，$\mu_i$为簇中心）实现聚类；&lt;/li&gt;
&lt;li&gt;关键优化：针对“分裂合并策略对聚类稳定性的影响”，设计“拆分最大距离簇+合并最近簇”的动态调整方案（替代原阈值法，避免聚类数爆炸），便于探索策略有效性；&lt;/li&gt;
&lt;li&gt;标签校准：通过“簇内真实标签占比最高者修正预测标签”，确保准确率计算可用于横向对比。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Soft K-means设计（服务探索目标）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心逻辑：引入概率权重 $w_{ij}$（数据$x_i$属于簇$j$的概率），目标函数优化为&lt;br&gt;
$$J=\sum_{i=1}^{n} \sum_{j=1}^{k} w_{ij}\left| x_{i}-\mu_{j}\right| ^{2}$$&lt;br&gt;
探索“概率化聚类”对准确率稳定性的提升；&lt;/li&gt;
&lt;li&gt;关键优化：针对“初始质心对收敛的影响”，设计“按距离平方概率分布选质心”的策略（先随机选1个质心，后续质心优先选择与已有质心距离远的样本），对比K-means随机初始化的效果；&lt;/li&gt;
&lt;li&gt;参数固定：β=0.7（经预实验确定，避免参数过多干扰探索结论）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-探索实验与结果分析&#34;&gt;2. 探索实验与结果分析
&lt;/h4&gt;&lt;p&gt;基于种子数据集（含3类种子，共210个样本），设计4组对比实验，探索核心参数影响：&lt;/p&gt;
&lt;h5 id=&#34;1容忍度影响探索k3无分裂合并&#34;&gt;（1）容忍度影响探索（k=3，无分裂合并）
&lt;/h5&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;模型&lt;/th&gt;
          &lt;th&gt;最大迭代&lt;/th&gt;
          &lt;th&gt;容忍度&lt;/th&gt;
          &lt;th&gt;准确率&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;300&lt;/td&gt;
          &lt;td&gt;1e-3&lt;/td&gt;
          &lt;td&gt;79.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;300&lt;/td&gt;
          &lt;td&gt;1e-4&lt;/td&gt;
          &lt;td&gt;79.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;300&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;79.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;300&lt;/td&gt;
          &lt;td&gt;1e-3&lt;/td&gt;
          &lt;td&gt;89.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;300&lt;/td&gt;
          &lt;td&gt;1e-4&lt;/td&gt;
          &lt;td&gt;89.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;300&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;89.52%&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;探索结论&lt;/strong&gt;：容忍度在$1e-3~1e-5$范围内，两类算法准确率均无变化，说明此参数对种子数据集聚类结果影响极小，后续实验可固定容忍度=1e-5（兼顾迭代效率与精度）。&lt;/p&gt;
&lt;h5 id=&#34;2迭代数影响探索k3容忍度1e-5&#34;&gt;（2）迭代数影响探索（k=3，容忍度=1e-5）
&lt;/h5&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;模型&lt;/th&gt;
          &lt;th&gt;最大迭代&lt;/th&gt;
          &lt;th&gt;容忍度&lt;/th&gt;
          &lt;th&gt;准确率&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;100&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;73.33%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;200&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;89.05%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;300&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;79.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;400&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;76.19%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;500&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;76.67%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;50&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;89.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;100&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;89.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;200&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;89.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;300&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;89.52%&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;探索结论&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;K-means：迭代数=200时准确率最高（89.05%），超200次后准确率下降（可能过拟合）；&lt;/li&gt;
&lt;li&gt;Soft K-means：迭代数≥50时准确率稳定在89.52%，无明显波动，说明其对迭代数敏感度更低，收敛更稳定。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;3聚类数与分裂合并策略影响探索迭代数200容忍度1e-5&#34;&gt;（3）聚类数与分裂合并策略影响探索（迭代数=200，容忍度=1e-5）
&lt;/h5&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;模型&lt;/th&gt;
          &lt;th&gt;聚类数&lt;/th&gt;
          &lt;th&gt;分裂合并&lt;/th&gt;
          &lt;th&gt;准确率&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;3&lt;/td&gt;
          &lt;td&gt;False&lt;/td&gt;
          &lt;td&gt;89.05%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;False&lt;/td&gt;
          &lt;td&gt;86.19%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;K-means&lt;/td&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;True&lt;/td&gt;
          &lt;td&gt;86.19%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;3&lt;/td&gt;
          &lt;td&gt;False&lt;/td&gt;
          &lt;td&gt;89.52%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;False&lt;/td&gt;
          &lt;td&gt;90.00%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Soft K-means&lt;/td&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;True&lt;/td&gt;
          &lt;td&gt;89.05%&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;探索结论&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;聚类数影响：K-means聚类数从3增至10时准确率下降3%，Soft K-means则提升0.48%，说明Soft K-means更适配多聚类场景；&lt;/li&gt;
&lt;li&gt;分裂合并策略影响：仅Soft K-means启用策略后准确率下降0.95%（种子数据簇分布紧凑，策略反而干扰聚类），K-means无变化，说明策略需结合数据分布使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;任务二pcalinear-autoencoder与soft-k-means图像重建探索&#34;&gt;任务二：PCA、Linear Autoencoder与Soft K-means图像重建探索
&lt;/h3&gt;&lt;h4 id=&#34;1-探索方向与算法实现&#34;&gt;1. 探索方向与算法实现
&lt;/h4&gt;&lt;p&gt;本次探索聚焦“&lt;strong&gt;算法类型、关键参数（保留维度/聚类数）对图像重建质量的影响&lt;/strong&gt;”，选择WWI士兵图像（256×256像素，低色彩复杂度，避免RGB通道干扰）为处理对象，三类算法实现均服务于探索目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PCA实现（探索“保留维度”影响）&lt;/strong&gt;：&lt;br&gt;
步骤：数据中心化→协方差矩阵计算&lt;br&gt;
$$C=\frac{1}{n} X_{centered }^{T} X_{centered }$$&lt;br&gt;
→SVD分解&lt;br&gt;
$$C=U \sum V^{T}$$&lt;br&gt;
→投影到前$k$主成分（$$X_{projected }=X_{centered } V[:,:k]$$）；&lt;br&gt;
重建：通过&lt;br&gt;
$$X_{recovered }=X_{projected } V[:,:k]^{T}+\mu$$&lt;br&gt;
还原图像，重点探索$k=1/2/3$时的效果差异。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Linear Autoencoder实现（探索“编码维度”影响）&lt;/strong&gt;：&lt;br&gt;
结构：输入层（图像像素）→编码层（$$E=X \cdot W_e$$）→解码层（$$D=E \cdot W_d$$）（无激活函数，纯线性变换）；&lt;br&gt;
训练：MSE损失&lt;br&gt;
$$loss =\frac{1}{m} \sum_{i=1}^{m}(D-X)^{2}$$&lt;br&gt;
，梯度裁剪避免爆炸（初始权重×0.00001防对称问题），重点探索编码维度=1/2/3时的重建误差。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Soft K-means实现（探索“聚类数”影响）&lt;/strong&gt;：&lt;br&gt;
逻辑：将图像像素视为样本，按聚类数$k$分配权重，用簇中心像素值替换原像素实现重建，重点探索$k=1/3/5/7/9$时的色彩与细节还原效果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-探索实验与结果分析-1&#34;&gt;2. 探索实验与结果分析
&lt;/h4&gt;&lt;h5 id=&#34;1pca与linear-autoencoder重建对比按维度&#34;&gt;（1）PCA与Linear Autoencoder重建对比（按维度）
&lt;/h5&gt;&lt;div style=&#34;display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; margin: 15px 0;&#34;&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/ai/图1.png&#34; alt=&#34;PCA图像重建效果&#34; style=&#34;max-width: 100%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图2：PCA重建效果（左→右：原图、n_components=1/2/3）&lt;/p&gt;
  &lt;/div&gt;
  &lt;div style=&#34;flex: 1 1 45%; text-align: center;&#34;&gt;
    &lt;img src=&#34;https://sxttrt.github.io/ai/图2.png&#34; alt=&#34;Linear Autoencoder重建效果&#34; style=&#34;max-width: 100%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
    &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图3：Linear Autoencoder重建效果（左→右：原图、encoding_size=1/2/3）&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;探索结论&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维度=1时：两类算法均输出灰度图（丢失色彩信息），Linear Autoencoder重建误差（0.015）略低于PCA（0.018）；&lt;/li&gt;
&lt;li&gt;维度=2时：Linear Autoencoder已呈现明显色彩（误差0.008），PCA仅轻微色彩（误差0.012），说明AE线性变换对特征保留更优；&lt;/li&gt;
&lt;li&gt;维度=3时：均与原图一致（RGB三通道完全保留），误差均为0。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;2soft-k-means重建对比按聚类数&#34;&gt;（2）Soft K-means重建对比（按聚类数）
&lt;/h5&gt;&lt;div style=&#34;text-align: center; margin: 15px 0;&#34;&gt;
  &lt;img src=&#34;https://sxttrt.github.io/ai/图3.png&#34; alt=&#34;Soft K-means不同聚类数重建效果&#34; style=&#34;max-width: 80%; border: 1px solid #eee; border-radius: 4px;&#34;&gt;
  &lt;p style=&#34;font-size: 14px; color: #666;&#34;&gt;图4：Soft K-means重建效果（上→下：k=1/3/5/7/9）&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;探索结论&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$k≤5$时：色彩断层明显（如$k=1$为单色图，$k=3$仅3种主色），细节模糊（士兵衣物纹理丢失）；&lt;/li&gt;
&lt;li&gt;$k=7~9$时：色彩逐渐丰富，$k=9$时覆盖所有像素主色，边缘细节（如帽子、衣领）基本还原，说明聚类数需匹配图像色彩复杂度（此图$k=9$为最优）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;任务三logistic-regression与mlp二分类探索x型分布数据&#34;&gt;任务三：Logistic Regression与MLP二分类探索（X型分布数据）
&lt;/h3&gt;&lt;h4 id=&#34;1-探索方向与算法实现-1&#34;&gt;1. 探索方向与算法实现
&lt;/h4&gt;&lt;p&gt;本次探索聚焦“&lt;strong&gt;模型类型（线性/非线性）、MLP超参数（隐藏层/神经元/容忍度）对二分类效果的影响&lt;/strong&gt;”，基于人工生成的X型分布数据（2维特征，两类样本呈交叉分布）设计实验：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Logistic Regression实现（线性模型基准）&lt;/strong&gt;：&lt;br&gt;
激活函数：Sigmoid&lt;br&gt;
$$\sigma(z)=\frac{1}{1+e^{-(w^T x + w_0)}}$$&lt;br&gt;
；&lt;br&gt;
训练：交叉熵损失&lt;br&gt;
$$loss =-\frac{1}{m} \sum_{i=1}^{m}[y_i log(h_i)+(1-y_i)log(1-h_i)]$$&lt;br&gt;
，梯度下降更新权重（$lr=0.01$，迭代=10000），探索线性模型对非线性数据的拟合局限。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MLP实现（非线性模型探索）&lt;/strong&gt;：&lt;br&gt;
结构：输入层（2维特征）→隐藏层（1-6层）→输出层（Sigmoid激活），支持自定义神经元数；&lt;br&gt;
优化：梯度裁剪控制梯度范围，重点探索“隐藏层数量（1/2/6）、神经元数（2/4/8/20）、容忍度（1e-5~1e-8）”对收敛与准确率的影响；&lt;br&gt;
停止条件：当两次迭代损失差绝对值＜容忍度时停止，记录收敛次数与最终准确率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-探索实验与结果分析-2&#34;&gt;2. 探索实验与结果分析
&lt;/h4&gt;&lt;h5 id=&#34;1线性vs非线性模型对比基础探索&#34;&gt;（1）线性vs非线性模型对比（基础探索）
&lt;/h5&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;模型&lt;/th&gt;
          &lt;th&gt;隐藏层/神经元&lt;/th&gt;
          &lt;th&gt;容忍度&lt;/th&gt;
          &lt;th&gt;准确率&lt;/th&gt;
          &lt;th&gt;收敛次数&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Logistic Regression&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;59.60%&lt;/td&gt;
          &lt;td&gt;10000（未收敛）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;1/8&lt;/td&gt;
          &lt;td&gt;1e-7&lt;/td&gt;
          &lt;td&gt;100.00%&lt;/td&gt;
          &lt;td&gt;8320&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;探索结论&lt;/strong&gt;：X型分布数据（非线性边界）无法被Logistic Regression有效拟合（准确率仅59.6%），而MLP（1隐藏层+8神经元）可完全拟合，说明非线性模型对复杂数据的适配优势。&lt;/p&gt;
&lt;h5 id=&#34;2mlp超参数影响探索&#34;&gt;（2）MLP超参数影响探索
&lt;/h5&gt;&lt;h6 id=&#34;-隐藏层与神经元数影响容忍度1e-7&#34;&gt;① 隐藏层与神经元数影响（容忍度=1e-7）
&lt;/h6&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;模型配置（隐藏层/神经元）&lt;/th&gt;
          &lt;th&gt;收敛次数&lt;/th&gt;
          &lt;th&gt;最终损失&lt;/th&gt;
          &lt;th&gt;损失变化趋势（对应图5曲线）&lt;/th&gt;
          &lt;th&gt;准确率&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1隐藏层+2神经元&lt;/td&gt;
          &lt;td&gt;1215&lt;/td&gt;
          &lt;td&gt;0.1523&lt;/td&gt;
          &lt;td&gt;快速收敛后停滞，损失居高不下&lt;/td&gt;
          &lt;td&gt;78.67%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1隐藏层+4神经元&lt;/td&gt;
          &lt;td&gt;8546&lt;/td&gt;
          &lt;td&gt;0.0253&lt;/td&gt;
          &lt;td&gt;缓慢收敛，损失逐步下降&lt;/td&gt;
          &lt;td&gt;98.67%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1隐藏层+8神经元&lt;/td&gt;
          &lt;td&gt;8320&lt;/td&gt;
          &lt;td&gt;0.0132&lt;/td&gt;
          &lt;td&gt;收敛速度中等，损失逼近最小值&lt;/td&gt;
          &lt;td&gt;100.00%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2隐藏层+3+6神经元&lt;/td&gt;
          &lt;td&gt;7264&lt;/td&gt;
          &lt;td&gt;0.0050&lt;/td&gt;
          &lt;td&gt;收敛平稳，损失最低且无波动&lt;/td&gt;
          &lt;td&gt;99.67%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;6隐藏层+2神经元&lt;/td&gt;
          &lt;td&gt;17&lt;/td&gt;
          &lt;td&gt;0.1628&lt;/td&gt;
          &lt;td&gt;瞬间收敛（未充分训练），损失高&lt;/td&gt;
          &lt;td&gt;77.00%&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;探索结论&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1隐藏层：神经元≥8时可完全拟合，神经元过少（2个）则拟合不足；&lt;/li&gt;
&lt;li&gt;2隐藏层：3+6神经元即可实现99.67%准确率，无需过多神经元；&lt;/li&gt;
&lt;li&gt;6隐藏层：即使神经元足够，仍因层数过多陷入局部最优（准确率77%），说明隐藏层并非越多越好。&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;-容忍度影响2隐藏层36神经元&#34;&gt;② 容忍度影响（2隐藏层+3/6神经元）
&lt;/h6&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;容忍度&lt;/th&gt;
          &lt;th&gt;收敛次数&lt;/th&gt;
          &lt;th&gt;损失&lt;/th&gt;
          &lt;th&gt;准确率&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1e-5&lt;/td&gt;
          &lt;td&gt;149&lt;/td&gt;
          &lt;td&gt;0.2489&lt;/td&gt;
          &lt;td&gt;53.67%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1e-6&lt;/td&gt;
          &lt;td&gt;43&lt;/td&gt;
          &lt;td&gt;0.2493&lt;/td&gt;
          &lt;td&gt;59.00%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1e-7&lt;/td&gt;
          &lt;td&gt;7264&lt;/td&gt;
          &lt;td&gt;0.0050&lt;/td&gt;
          &lt;td&gt;99.67%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1e-8&lt;/td&gt;
          &lt;td&gt;8120&lt;/td&gt;
          &lt;td&gt;0.0048&lt;/td&gt;
          &lt;td&gt;99.50%&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;探索结论&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容忍度≥1e-6时：损失早停（未充分拟合），准确率仅53.67%~59%；&lt;/li&gt;
&lt;li&gt;容忍度=1e-7~1e-8时：损失充分收敛，准确率≥99.5%，但1e-8时因过度迭代出现轻微过拟合（准确率微降0.17%），最优容忍度为1e-7。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;四项目成果与附件&#34;&gt;四、项目成果与附件
&lt;/h2&gt;&lt;h3 id=&#34;1-论文预览与下载&#34;&gt;1. 论文预览与下载
&lt;/h3&gt;&lt;h4 id=&#34;11-论文1基于k-meanspca与linear-autoencoder的分类与图像处理研究&#34;&gt;1.1 论文1：基于K-means、PCA与Linear Autoencoder的分类与图像处理研究
&lt;/h4&gt;&lt;iframe src=&#34;https://sxttrt.github.io/ai/K-means_PCA_LinearAutoencoder_Research.pdf&#34; width=&#34;100%&#34; height=&#34;700&#34; style=&#34;border: 1px solid #e0e0e0; border-radius: 6px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);&#34; title=&#34;论文1：基于K-means、PCA与Linear Autoencoder的分类与图像处理研究&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;若浏览器加载缓慢或无法预览，可直接下载：
&lt;a href=&#34;https://sxttrt.github.io/ai/K-means_PCA_LinearAutoencoder_Research.pdf&#34; target=&#34;_blank&#34;&gt;K-means_PCA_LinearAutoencoder_Research.pdf 下载链接&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;12-论文2基于logistic-regression与mlp的二分类算法探索&#34;&gt;1.2 论文2：基于Logistic Regression与MLP的二分类算法探索
&lt;/h4&gt;&lt;iframe src=&#34;https://sxttrt.github.io/ai/LogisticRegression_MLP_BinaryClassification.pdf&#34; width=&#34;100%&#34; height=&#34;700&#34; style=&#34;border: 1px solid #e0e0e0; border-radius: 6px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-top: 30px;&#34; title=&#34;论文2：基于Logistic Regression与MLP的二分类算法探索&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;若浏览器加载缓慢或无法预览，可直接下载：
&lt;a href=&#34;https://sxttrt.github.io/ai/LogisticRegression_MLP_BinaryClassification.pdf&#34; target=&#34;_blank&#34;&gt;LogisticRegression_MLP_BinaryClassification.pdf 下载链接&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-核心探索成果规律总结&#34;&gt;2. 核心探索成果（规律总结）
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;探索方向&lt;/th&gt;
          &lt;th&gt;关键结论&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;聚类分类&lt;/td&gt;
          &lt;td&gt;1. Soft K-means比K-means更稳定（准确率波动≤0.5% vs 3%），多聚类场景（k=10）更优；&lt;br&gt;2. 分裂合并策略仅适用于簇分布松散数据，种子数据（紧凑分布）启用后准确率下降0.95%；&lt;br&gt;3. 容忍度（1e-3~1e-5）对聚类结果影响极小，迭代数需匹配算法（K-means=200，Soft K-means≥50）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;图像重建&lt;/td&gt;
          &lt;td&gt;1. PCA需保留3维（RGB通道）才能完全还原图像，Linear Autoencoder 2维即可实现低误差（0.008）；&lt;br&gt;2. Soft K-means聚类数需匹配图像色彩复杂度，WWI士兵图k=9时细节还原最佳；&lt;br&gt;3. Linear Autoencoder对初始权重敏感，随机权重易导致重建失败&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;二分类&lt;/td&gt;
          &lt;td&gt;1. 非线性数据（X型分布）需用MLP（非线性模型），Logistic Regression（线性）准确率仅59.6%；&lt;br&gt;2. MLP最优配置：1~2隐藏层+8/3+6神经元，容忍度=1e-7（平衡收敛与过拟合）；&lt;br&gt;3. 隐藏层≥6时易陷入局部最优，准确率骤降22%+&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        
    </channel>
</rss>
